{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week05\n",
    "\n",
    "Lets continue discussing the detials of Regression. In particular, we can write down the maximum likelhood estimators for $\\beta_{0}$, $\\beta_{1}$, and $\\sigma^{2}$.\n",
    "Next we will write down the Fisher Infromation **Matrix** for a 2X1 vector that contains $\\beta_{0}$ and $\\beta_{1}$.\n",
    "\n",
    "With our MLE and Fisher Infromation Matrix we can compute confidence intervals for $\\beta$ and setup hypothesis tests. \n",
    "\n",
    "Our goal this week is to:\n",
    "1. Write down the solution to the loglikelihood\n",
    "2. Write down and understand how to use the Fisher Information\n",
    "3. Learn how to build Confidnece intervals for $\\beta$\n",
    "4. Learn how to compute fitted values $\\hat{\\mu(x)}$\n",
    "5. Briefly discuss the \"true\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The solution to the loglikelihood (ie the MLEs for $\\beta_{0}$, $\\beta_{1}$, and $\\sigma^{2}$)\n",
    "\n",
    "The MLE of $\\beta_{1}$ ($\\hat \\beta_{1}$) is \n",
    "\n",
    "\\begin{align}\n",
    "    \\hat \\beta_{1} = \\dfrac{ \\sum_{i=1}^{N}(x_{i} - \\bar{x})(y_{i} - \\bar{y}) }{ \\sum_{i=1}^{N} (x_{i} - \\bar{x})^{2}  }\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "The MLE of $\\beta_{0}$  ($\\hat \\beta_{0}$) is \n",
    "\n",
    "\\begin{align}\n",
    "    \\hat \\beta_{0} = \\bar{y} - \\hat{\\beta_{1}}\\bar{x}\n",
    "\\end{align}\n",
    "\n",
    "The MLE for $\\sigma^{2}$ is worth some discussion of the model form for SLR.\n",
    "Recall SLR model form is \n",
    "\n",
    "\\begin{align}\n",
    "    y_{i} &= \\beta_{0} + \\beta_{1}x_{i} + \\epsilon_{i} \\\\ \n",
    "          \\epsilon_{i} & \\sim \\mathcal{N}\\left(0,\\sigma^{2}\\right)\n",
    "\\end{align}\n",
    "\n",
    "In model form we see that given estimates for $\\beta_{0}$ and $\\beta_{1}$ we can compute $\\epsilon_{i}$ values.\n",
    "Lets plug in our MLE estimates for $\\beta_{0}$ and $\\beta_{1}$ and solve for  $\\epsilon_{i}$:\n",
    "\n",
    "\\begin{align}\n",
    "    y_{i} &= \\beta_{0} + \\beta_{1}x_{i} + \\epsilon_{i} \\\\ \n",
    "    y_{i} &= \\hat \\beta_{0} + \\hat \\beta_{1}x_{i} + \\epsilon_{i} \\\\ \n",
    "    \\epsilon_{i} &= y_{i} - \\left(\\hat \\beta_{0} + \\hat \\beta_{1}x_{i} \\right)\n",
    "\\end{align}\n",
    "\n",
    "We can consider each \\epsilon_{i} as a data point.\n",
    "Our data is $\\epsilon = [\\epsilon_{1},\\epsilon_{2},\\cdots,\\epsilon_{N}]$ and our model is \n",
    "\n",
    "\\begin{align}\n",
    "    E_{i} \\sim \\mathcal{N}\\left(0,\\sigma^{2} \\right)\n",
    "\\end{align}\n",
    "\n",
    "We know from previous work that the MLE for $\\sigma^{2}$ of this model is \n",
    "\n",
    "\\begin{align}\n",
    "    \\hat \\sigma^{2} = \\dfrac{ (\\epsilon_{i} - \\bar{\\epsilon})^{2} }{N}\n",
    "\\end{align}\n",
    "\n",
    "and by assumption, and the Law of Large Numbers, we expect $\\bar{\\epsilon} \\approx 0$ sp \n",
    "\n",
    "\\begin{align}\n",
    "    \\hat \\sigma^{2} &= \\dfrac{ (\\epsilon_{i} - 0)^{2} }{N} \\\\ \n",
    "    \\hat \\sigma^{2} &= \\dfrac{ \\epsilon_{i}^{2} }{N} \\\\ \n",
    "\\end{align}\n",
    "\n",
    "Though the above is the MLE for \\hat \\sigma^{2} it is more traditional to estimate $\\hat \\sigma^{2}$ as \n",
    "\n",
    "\\begin{align}\n",
    "    \\hat \\sigma^{2} &= \\dfrac{ \\epsilon_{i}^{2} }{N-2} \\\\ \n",
    "\\end{align}\n",
    "\n",
    "### Fitted values\n",
    "\n",
    "Assume data $\\mathcal{D} = [ (x_{1},y_{1}),(x_{2},y_{2}),\\cdots,(x_{N},y_{N})]$\n",
    "and the following model \n",
    "\n",
    "\\begin{align}\n",
    "    Y_{i} | x_{i} \\sim \\mathcal{N}\\left(\\mu(x_{i}), \\sigma^{2} \\right)\n",
    "\\end{align}\n",
    "\n",
    "where \n",
    "\n",
    "\\begin{align}\n",
    "    \\mu(x_{i}) =  \\beta_{0} + \\beta_{1}x_{i}\n",
    "\\end{align}\n",
    "\n",
    "Then $E(Y_{i}|x_{i}) = \\mu(x_{i}) =  \\beta_{0} + \\beta_{1}x_{i}$ and the MLE estimate of $\\mu(x_{i})$, denoted $\\hat \\mu(x_{i})$ is called a **fitted value** for $Y_{i}$.\n",
    "A **fitted value** for $Y_{i}$ assuming a SLR model is \n",
    "\n",
    "\\begin{align}\n",
    "    \\hat \\mu(x_{i}) = \\hat \\beta_{0} + \\hat \\beta_{1} x_{i}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating parameters as a vector and the Fisher Information Matrix\n",
    "\n",
    "Up until now we have specificed our data and model for individual data points/random variables. \n",
    "Let us reformulate our data and model using Matrix algebra (because it is awesome). \n",
    "\n",
    "Assume data $\\mathcal{D} = [ (x_{1},y_{1}),(x_{2},y_{2}),\\cdots,(x_{N},y_{N})]$\n",
    "Our model says that each random variable $Y_{i}$ has the following distribution \n",
    "\n",
    "\\begin{align}\n",
    "    Y_{1}  = 1\\beta_{0} + x_{1}\\beta_{1} + \\epsilon_{1}\\\\\n",
    "    Y_{2}  = 1\\beta_{0} + x_{2}\\beta_{1} + \\epsilon_{2}\\\\\n",
    "    Y_{3}  = 1\\beta_{0} + x_{3}\\beta_{1} + \\epsilon_{3}\\\\\n",
    "    Y_{4}  = 1\\beta_{0} + x_{4}\\beta_{1} + \\epsilon_{4}\\\\\n",
    "    Y_{5}  = 1\\beta_{0} + x_{5}\\beta_{1} + \\epsilon_{5}\n",
    "\\end{align}    \n",
    "\n",
    "where each $\\epsilon_{i} \\sim \\mathcal{N}\\left(0,\\sigma^{2}\\right)$.\n",
    "\n",
    "This model can be rewritten as \n",
    "\n",
    "\\begin{align}\n",
    "    Y = X\\beta + \\epsilon\n",
    "\\end{align}\n",
    "\n",
    "where \n",
    "\n",
    "\\begin{align}\n",
    "    Y  = \\left[\\begin{matrix}\n",
    "               Y_{1}\\\\\n",
    "               Y_{2}\\\\\n",
    "               Y_{3}\\\\\n",
    "               Y_{4}\\\\\n",
    "               Y_{5}\n",
    "          \\end{matrix}\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\epsilon  = \\left[\\begin{matrix}\n",
    "               \\epsilon_{1}\\\\\n",
    "               \\epsilon_{2}\\\\\n",
    "               \\epsilon_{3}\\\\\n",
    "               \\epsilon_{4}\\\\\n",
    "               \\epsilon_{5}\n",
    "          \\end{matrix}\\right]\n",
    "\\end{align}\n",
    "\n",
    "where each $\\epsilon_{i}$ is normally distributed with parameter $\\sigma^{2}$ or \n",
    "$\\epsilon_{i} \\sim \\mathcal{N}\\left(0,\\sigma^{2}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    X  = \\left[\\begin{matrix}\n",
    "               1 & x_{1} \\\\ \n",
    "               1 & x_{2} \\\\ \n",
    "               1 & x_{3} \\\\ \n",
    "               1 & x_{4} \\\\ \n",
    "               1 & x_{5} \\\\  \n",
    "          \\end{matrix}\\right]\n",
    "\\end{align}\n",
    "\n",
    "and finally\n",
    "\n",
    "\\begin{align}\n",
    "    \\beta = \\left[\\begin{matrix}\n",
    "                    \\beta_{0} \\\\ \n",
    "                    \\beta_{1}\\\\\n",
    " \\end{matrix}\\right]\n",
    "\\end{align}                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Multivariate Normal distribution and probabilities over vectors\n",
    "\n",
    "Because we have re-expressed our Simple linear regression using matrices and vectors, we need a way to talk about probabilities over vectors. To be clear, we rewrote our SLR  \n",
    "\n",
    "\\begin{align}\n",
    "    Y \\sim \\text{Some Distribution}( X\\beta, \\Sigma )\n",
    "\\end{align}\n",
    "\n",
    "But how should we characterize a vector where each entry in the vector has a Normal Distribution? \n",
    "\n",
    "#### The Multivariate Normal Distribution (MVN)\n",
    "\n",
    "The multivariate distribution uses a probability density over vectors to assign with assigning probabilities over intervals. For a **random vector** $x = [x_{1},x_{2},\\cdots,x_{N}]'$ the MVN Normal distribution is denoted \n",
    "\n",
    "\\begin{align}\n",
    "    x \\sim MVN\\left( \\mu, \\Sigma \\right)\n",
    "\\end{align}\n",
    "\n",
    "where $\\mu = [\\mu_{1},\\mu_{2},\\cdots,\\mu_{N}]$ is a mean vector and \n",
    "\n",
    "\\begin{align}\n",
    "    \\Sigma = \\left [ \\begin{matrix}\n",
    "                           \\sigma_{x_{1}}^{2}    & \\sigma_{x_{1},x_{2}} &\\cdots &\\sigma_{x_{1},x_{N}}\\\\\n",
    "                           \\sigma_{x_{1},x_{2} } & \\sigma_{x_{2}}^{2}   &\\cdots &\\sigma_{x_{2},x_{N}}\\\\\n",
    "                           \\vdots\n",
    "                      \\end{matrix} \\right ]\n",
    "\\end{align}\n",
    "\n",
    "is called the covariance matrix where diagnoal entries in this matrix $\\Sigma_{ii}$ are equal to the variance of $x_{i}$ and entries $\\Sigma_{ij}$ are equal to the covariance between $x_{i}$ and $x_{j}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
